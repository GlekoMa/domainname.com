{
  "hash": "1111bde6a92ac3e223c2fe4aa99d0e3c",
  "result": {
    "markdown": "---\ntitle: 习题7.6\nfig-height: 3\nfig-width: 5\n---\n\n> **一家大型商业银行有多家分行，近年来，该银行的贷款额平稳增长，但不良贷款额也有较大比例的提高。为弄清楚不良贷款形成的原因，希望利用银行业务的有关数据做些定量分析，以便找出控制不良贷款的办法。下表是该银行所属25家分行2002年的有关业务数据。**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\ndata = read_sav(\"data/xt7.6.sav\", encoding=\"gbk\")\nhead(data)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 6 × 6\n  分行编号     y    x1    x2    x3    x4\n     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1        1   0.9  67.3   6.8     5  51.9\n2        2   1.1 111.   19.8    16  90.9\n3        3   4.8 173     7.7    17  73.7\n4        4   3.2  80.8   7.2    10  14.5\n5        5   7.8 200.   16.5    19  63.2\n6        6   2.7  16.2   2.2     1   2.2\n```\n:::\n:::\n\n#### 1. 计算$y$与其余4个变量的简单相关系数\n\n::: {.cell}\n\n```{.r .cell-code}\ndata = data[, -1] # 删去分行编号\ncor(data)\n```\n\n::: {.cell-output-stdout}\n```\n           y        x1        x2        x3        x4\ny  1.0000000 0.8435714 0.7315050 0.7002815 0.5185181\nx1 0.8435714 1.0000000 0.6787718 0.8484164 0.7797022\nx2 0.7315050 0.6787718 1.0000000 0.5858315 0.4724310\nx3 0.7002815 0.8484164 0.5858315 1.0000000 0.7466458\nx4 0.5185181 0.7797022 0.4724310 0.7466458 1.0000000\n```\n:::\n:::\n\n#### 2. 建立不良贷款$y$对4个自变量的线性回归方程，所得的回归系数是否合理？\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel = lm(y ~., data)\nmodel\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ ., data = data)\n\nCoefficients:\n(Intercept)           x1           x2           x3           x4  \n   -1.02164      0.04004      0.14803      0.01453     -0.02919  \n```\n:::\n:::\n\n#### 3. 分析回归模型的共线性\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nvif(model)\n```\n\n::: {.cell-output-stdout}\n```\n      x1       x2       x3       x4 \n5.330807 1.889860 3.834823 2.781220 \n```\n:::\n:::\n\n#### 4. 采用后退法和逐步回归法选择变量，所得回归方程的回归系数是否合理，是否还存在共线性？\n\n::: {.cell}\n\n```{.r .cell-code}\n# 后退法\nmodel_back = step(model, direction=\"backward\", trace=0)\nmodel_back\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = data)\n\nCoefficients:\n(Intercept)           x1           x2           x4  \n   -0.97160      0.04104      0.14886     -0.02850  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 逐步回归法\nmodel_both = step(model, direction=\"both\", trace=0)\nmodel_both\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = data)\n\nCoefficients:\n(Intercept)           x1           x2           x4  \n   -0.97160      0.04104      0.14886     -0.02850  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_both)\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8531 -0.8766 -0.3685  0.9586  3.0772 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.971605   0.711240  -1.366   0.1864    \nx1           0.041039   0.008525   4.814 9.31e-05 ***\nx2           0.148858   0.076817   1.938   0.0662 .  \nx4          -0.028502   0.014206  -2.006   0.0579 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.737 on 21 degrees of freedom\nMultiple R-squared:  0.7973,\tAdjusted R-squared:  0.7683 \nF-statistic: 27.53 on 3 and 21 DF,  p-value: 1.802e-07\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 = lm(y ~ x1 + x4, data)\nsummary(model2)\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x4, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7178 -1.1585 -0.3882  1.2416  5.0093 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.443424   0.696865  -0.636   0.5311    \nx1           0.050332   0.007477   6.732 9.14e-07 ***\nx4          -0.031903   0.014954  -2.133   0.0443 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.843 on 22 degrees of freedom\nMultiple R-squared:  0.761,\tAdjusted R-squared:  0.7393 \nF-statistic: 35.03 on 2 and 22 DF,  p-value: 1.45e-07\n```\n:::\n:::\n\n\n#### 5. 建立不良贷款$y$对4个自变量的岭回归\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\n# 与课本所言不同，lm.ridge函数会自动对变量进行标准化\n# 但又如课本所言，lm.ridge的岭参数 == k*n\n# 下面计算k属于(0, 0.2)时的岭回归\nn = nrow(data)\nridge = lm.ridge(y ~., \n                 data, \n                 lambda=seq(0, 0.2*n, 0.1)*nrow(data))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 岭迹图\n# 注：x轴刻度除以n为k值\nplot(ridge)\n```\n\n::: {.cell-output-display}\n![](xt7.6_files/figure-html/unnamed-chunk-10-1.png){width=480}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 附：编写函数，输入原始数据，返回ggplot岭迹图\nggplot_ridge = function(data){\n    # 标准化与岭回归\n    library(MASS)\n    data_scaled = as.data.frame(scale(data))\n    ridge = lm.ridge(y ~., data_scaled, lambda=seq(0, 2, 0.1))\n\n    coef_ridge = as.data.frame(coef(ridge))\n    coef_ridge[, 1] = row.names(coef_ridge)\n    nrow_cr = nrow(coef_ridge)\n    ncol_cr = ncol(coef_ridge)\n\n    # 宽列表转换为长列表\n    library(tidyr)\n    coef_ridge_long = pivot_longer(coef_ridge, \n                                  cols=2:all_of(ncol_cr),\n                                  names_to = \"beta\", \n                                  values_to = \"value\")\n\n    # 岭迹图\n    library(ggplot2)\n    p = ggplot(coef_ridge_long, aes(x=V1, y=value, group=beta, color=beta)) + \n        geom_smooth(se=FALSE) + \n        labs(x=\"k\") +  \n        theme_minimal()\n\n    # 岭迹图修饰\n    library(latex2exp)\n    df = coef_ridge[nrow_cr, ]\n    pos = as.numeric(df[, -1])\n    p = p + \n          guides(color=\"none\") + \n          labs(y=TeX(r\"($\\bar{\\beta}_j(k)$)\")) + \n          theme(axis.title.x=element_text(hjust=1),\n                axis.title.y=element_text(hjust=1, angle=1))\n    for (i in 1:length(pos)){\n      p = p + annotate(geom=\"text\", \n                       x=df[, 1], \n                       y=pos[i], \n                       label=as.character(i),\n                       vjust=-1)\n    }\n\n    return(p)\n}\nggplot_ridge(data)\n```\n\n::: {.cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](xt7.6_files/figure-html/unnamed-chunk-11-1.png){width=480}\n:::\n:::\n\n#### 6. 对第（4）步剔除变量后的回归方程再做岭回归\n\n::: {.cell}\n\n```{.r .cell-code}\n# 编写函数，将标准化回归方程参数转化未标准化方程参数\n# 数据必须为tibble类型，变量顺序必须为y, x1, x2...\nunscale = function(data, coef){\n    my_sd = \\(x) (mean((x-mean(x))^2))^0.5 # 定义计算总体标准差函数my_sd\n    coef_sd = apply(data[, -1], 2, my_sd)\n    coef_mean = apply(data[, -1], 2, mean)\n    beta_j = coef / coef_sd\n    beta_0 = sum(beta_j * -coef_mean) + apply(data[, 1], 2, mean)\n    names(beta_0) = \"Intercept\"\n    return(c(beta_0, beta_j))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata0 = data[, c(\"y\", \"x1\", \"x4\")]\nridge = lm.ridge(y ~ ., data0, lambda=seq(0, 2*n, 0.1))\nplot(ridge)\n```\n\n::: {.cell-output-display}\n![](xt7.6_files/figure-html/unnamed-chunk-13-1.png){width=480}\n:::\n\n```{.r .cell-code}\n# 计算岭参数为0.4时的未标准化岭回归方程\nridge = lm.ridge(y ~ ., data0, lambda=0.4*n)\nunscale(data0, ridge$coef)\n```\n\n::: {.cell-output-stdout}\n```\n  Intercept          x1          x4 \n0.357087614 0.025805860 0.004531316 \n```\n:::\n:::\n\n#### 7. 某研究人员希望做$y$对各项贷款余额、本年累计应收贷款、贷款项目个数这3个自变量的回归，你认为这样做是否可行？如果可行应该如何做？\n\n::: {.cell}\n\n```{.r .cell-code}\ndata1 = data[, c(\"y\", \"x1\", \"x2\", \"x3\")]\nridge = lm.ridge(y ~ ., data1, lambda=seq(0, 2*n, 0.1))\nplot(ridge)\n```\n\n::: {.cell-output-display}\n![](xt7.6_files/figure-html/unnamed-chunk-14-1.png){width=480}\n:::\n\n```{.r .cell-code}\nunscale(data1, 0.4)\n```\n\n::: {.cell-output-stdout}\n```\n  Intercept          x1          x2          x3 \n1.772323628 0.005081094 0.064445807 0.047675297 \n```\n:::\n:::\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "xt7.6_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}