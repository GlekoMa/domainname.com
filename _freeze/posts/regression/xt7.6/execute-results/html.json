{
  "hash": "b91e59a7b8a77c61c3ed56871b45ae51",
  "result": {
    "markdown": "---\ntitle: 习题7.6\ndescription: 岭回归\n---\n\n> **一家大型商业银行有多家分行，近年来，该银行的贷款额平稳增长，但不良贷款额也有较大比例的提高。为弄清楚不良贷款形成的原因，希望利用银行业务的有关数据做些定量分析，以便找出控制不良贷款的办法。下表是该银行所属25家分行2002年的有关业务数据。**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\ndata = read_sav(\"data/xt7.6.sav\", encoding=\"gbk\")\nhead(data)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 6 × 6\n  分行编号     y    x1    x2    x3    x4\n     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1        1   0.9  67.3   6.8     5  51.9\n2        2   1.1 111.   19.8    16  90.9\n3        3   4.8 173     7.7    17  73.7\n4        4   3.2  80.8   7.2    10  14.5\n5        5   7.8 200.   16.5    19  63.2\n6        6   2.7  16.2   2.2     1   2.2\n```\n:::\n:::\n\n#### 1. 计算$y$与其余4个变量的简单相关系数\n\n::: {.cell}\n\n```{.r .cell-code}\ndata = data[, -1] # 删去分行编号\ncor(data)\n```\n\n::: {.cell-output-stdout}\n```\n           y        x1        x2        x3        x4\ny  1.0000000 0.8435714 0.7315050 0.7002815 0.5185181\nx1 0.8435714 1.0000000 0.6787718 0.8484164 0.7797022\nx2 0.7315050 0.6787718 1.0000000 0.5858315 0.4724310\nx3 0.7002815 0.8484164 0.5858315 1.0000000 0.7466458\nx4 0.5185181 0.7797022 0.4724310 0.7466458 1.0000000\n```\n:::\n:::\n\n答：可以看出，$y$与自变量$x_1,x_2,x_3,x_4$间的线性相关性较强，但同时自变量间的线性相关性也普遍较强（相关系数接近1）。\n\n#### 2. 建立不良贷款$y$对4个自变量的线性回归方程，所得的回归系数是否合理？\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel = lm(y ~., data)\nsummary(model)\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ ., data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9198 -0.9507 -0.2880  1.0334  3.1037 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) -1.02164    0.78237  -1.306  0.20643   \nx1           0.04004    0.01043   3.837  0.00103 **\nx2           0.14803    0.07879   1.879  0.07494 . \nx3           0.01453    0.08303   0.175  0.86285   \nx4          -0.02919    0.01507  -1.937  0.06703 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.779 on 20 degrees of freedom\nMultiple R-squared:  0.7976,\tAdjusted R-squared:  0.7571 \nF-statistic:  19.7 on 4 and 20 DF,  p-value: 1.035e-06\n```\n:::\n:::\n\n答：在所建立的回归模型中，自变量$x_2,x_3,x_4$未通过t检验（P值>0.05），回归系数$\\beta_2,\\beta_3,\\beta_4$不显著。由实际问题来看，$x_4$的系数显然不能为负，故所得的回归系数不合理。\n\n#### 3. 分析回归模型的共线性\n\n**方差扩大因子法**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nvif(model)\n```\n\n::: {.cell-output-stdout}\n```\n      x1       x2       x3       x4 \n5.330807 1.889860 3.834823 2.781220 \n```\n:::\n:::\n\n**特征根判定法**\n\n::: {.cell}\n\n```{.r .cell-code}\nCor = cor(data[, 2:5])\nkappa(Cor, exact=TRUE)\n```\n\n::: {.cell-output-stdout}\n```\n[1] 23.23595\n```\n:::\n:::\n\n答：由方差扩大因子法，未见多重共线性；由特征根判定法，条件数k=23.24>10，模型存在较强多重共线性。\n\n#### 4. 采用后退法和逐步回归法选择变量，所得回归方程的回归系数是否合理，是否还存在共线性？\n\n::: {.cell}\n\n```{.r .cell-code}\n# 后退法\nmodel_back = step(model, direction=\"backward\", trace=0)\nmodel_back\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = data)\n\nCoefficients:\n(Intercept)           x1           x2           x4  \n   -0.97160      0.04104      0.14886     -0.02850  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 逐步回归法\nmodel_both = step(model, direction=\"both\", trace=0)\nmodel_both\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = data)\n\nCoefficients:\n(Intercept)           x1           x2           x4  \n   -0.97160      0.04104      0.14886     -0.02850  \n```\n:::\n:::\n\n*后退法和逐步回归法筛选出的变量相同*\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_both)\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8531 -0.8766 -0.3685  0.9586  3.0772 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.971605   0.711240  -1.366   0.1864    \nx1           0.041039   0.008525   4.814 9.31e-05 ***\nx2           0.148858   0.076817   1.938   0.0662 .  \nx4          -0.028502   0.014206  -2.006   0.0579 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.737 on 21 degrees of freedom\nMultiple R-squared:  0.7973,\tAdjusted R-squared:  0.7683 \nF-statistic: 27.53 on 3 and 21 DF,  p-value: 1.802e-07\n```\n:::\n:::\n\n*删去不显著的自变量$x_2$，重新建立回归模型*\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 = lm(y ~ x1 + x4, data)\nsummary(model2)\n```\n\n::: {.cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x4, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7178 -1.1585 -0.3882  1.2416  5.0093 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.443424   0.696865  -0.636   0.5311    \nx1           0.050332   0.007477   6.732 9.14e-07 ***\nx4          -0.031903   0.014954  -2.133   0.0443 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.843 on 22 degrees of freedom\nMultiple R-squared:  0.761,\tAdjusted R-squared:  0.7393 \nF-statistic: 35.03 on 2 and 22 DF,  p-value: 1.45e-07\n```\n:::\n:::\n\n答：回归方程为：$\\hat{y} = -0.443+0.05x_1-0.032x_4$。$x_4$系数为负，不合常理，说明存在多重共线性。\n\n#### 5. 建立不良贷款$y$对4个自变量的岭回归\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\n# 与课本所言不同，lm.ridge函数会自动对变量进行标准化\n# 但又如课本所言，lm.ridge的岭参数 == k*n\n# 下面计算k属于(0, 0.2)时的岭回归\nn = nrow(data)\nridge = lm.ridge(y ~., \n                 data, \n                 lambda=seq(0, 0.2*n, 0.1)*nrow(data))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 岭迹图\n# 注：x轴刻度除以n为k值\nplot(ridge)\n```\n\n::: {.cell-output-display}\n![](xt7.6_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 附：编写函数，输入原始数据，返回ggplot岭迹图\nggplot_ridge = function(data){\n    # 标准化与岭回归\n    library(MASS)\n    data_scaled = as.data.frame(scale(data))\n    ridge = lm.ridge(y ~., data_scaled, lambda=seq(0, 2*nrow(data), 0.2*nrow(data)))\n\n    coef_ridge = as.data.frame(coef(ridge))\n    coef_ridge[, 1] = row.names(coef_ridge)\n    nrow_cr = nrow(coef_ridge)\n    ncol_cr = ncol(coef_ridge)\n\n    # 宽列表转换为长列表\n    library(tidyr)\n    coef_ridge_long = pivot_longer(coef_ridge, \n                                  cols=2:all_of(ncol_cr),\n                                  names_to = \"beta\", \n                                  values_to = \"value\")\n\n    # 岭迹图\n    library(ggplot2)\n    p = ggplot(coef_ridge_long, aes(x=V1, y=value, group=beta, color=beta)) + \n        geom_smooth(se=FALSE)\n\n    # 岭迹图修饰\n    library(latex2exp)\n    df = coef_ridge[nrow_cr, ]\n    pos = as.numeric(df[, -1])\n    p = p + \n          guides(color=\"none\") + \n          labs(x=TeX(r\"($k\\times n$)\"),\n               y=TeX(r\"($\\bar{\\beta}_j(k)$)\")) + \n          theme(axis.title.x=element_text(hjust=1),\n                axis.title.y=element_text(hjust=1, angle=1)) + \n          theme_minimal()\n    for (i in 1:length(pos)){\n      p = p + annotate(geom=\"text\", \n                       x=df[, 1], \n                       y=pos[i], \n                       label=as.character(i),\n                       vjust=-0.2)\n    }\n\n    return(p)\n}\nggplot_ridge(data)\n```\n\n::: {.cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](xt7.6_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n答：由岭迹图，随着岭参数k的增大，$\\beta_4$由负变正。\n\n#### 6. 对第（4）步剔除变量后的回归方程再做岭回归\n\n::: {.cell}\n\n```{.r .cell-code}\n# 编写函数，将标准化回归方程参数转化未标准化方程参数\n# 数据必须为tibble类型，变量顺序必须为y, x1, x2...\nunscale = function(data, coef){\n    my_sd = \\(x) (mean((x-mean(x))^2))^0.5 # 定义计算总体标准差函数my_sd\n    coef_sd = apply(data[, -1], 2, my_sd)\n    coef_mean = apply(data[, -1], 2, mean)\n    beta_j = coef / coef_sd\n    beta_0 = sum(beta_j * -coef_mean) + apply(data[, 1], 2, mean)\n    names(beta_0) = \"Intercept\"\n    return(c(beta_0, beta_j))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata0 = data[, c(\"y\", \"x1\", \"x4\")]\nridge = lm.ridge(y ~ ., data0, lambda=seq(0, 2*n, 0.1))\nplot(ridge)\n```\n\n::: {.cell-output-display}\n![](xt7.6_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n*由岭迹图，岭参数为0.4时的回归系数较为稳定，遂此时的未标准化岭回归方程*\n\n::: {.cell}\n\n```{.r .cell-code}\nridge = lm.ridge(y ~ ., data0, lambda=0.4*n)\nunscale(data0, ridge$coef)\n```\n\n::: {.cell-output-stdout}\n```\n  Intercept          x1          x4 \n0.357087614 0.025805860 0.004531316 \n```\n:::\n:::\n\n答：回归方程为：$\\hat{y}=0.357+0.0258x_1+0.0045x_2$。回归系数都能合理解释。\n\n#### 7. 某研究人员希望做$y$对各项贷款余额、本年累计应收贷款、贷款项目个数这3个自变量的回归，你认为这样做是否可行？如果可行应该如何做？\n\n*用$y$对$x_1,x_2,x_3$做岭回归*\n\n::: {.cell}\n\n```{.r .cell-code}\ndata1 = data[, c(\"y\", \"x1\", \"x2\", \"x3\")]\nridge = lm.ridge(y ~ ., data1, lambda=seq(0, 2*n, 0.1))\nplot(ridge)\n```\n\n::: {.cell-output-display}\n![](xt7.6_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n*选取岭参数k=0.4*\n\n::: {.cell}\n\n```{.r .cell-code}\nridge = lm.ridge(y ~ ., data1, lambda=0.4*n)\nunscale(data1, ridge$coef)\n```\n\n::: {.cell-output-stdout}\n```\n  Intercept          x1          x2          x3 \n-0.81948673  0.01673907  0.15680666  0.06711093 \n```\n:::\n:::\n\n答：回归方程为：$\\hat{y}=-0$\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "xt7.6_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}